{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты, просмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss, roc_auc_score\n",
    "from typing import Dict, List, Union\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"D:/Datasets/HSE/Project/EDA/df_l_fin.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>hubs</th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "      <th>url</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>individ/company</th>\n",
       "      <th>bookmarks_cnt</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tags_tokens</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>rating_new</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complex</td>\n",
       "      <td>2009-08-03 14:34:35+00:00</td>\n",
       "      <td>GTD</td>\n",
       "      <td>67</td>\n",
       "      <td>6800</td>\n",
       "      <td>https://habr.com/ru/articles/66091/</td>\n",
       "      <td>2.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2027</td>\n",
       "      <td>['лень' 'учись' 'работать' 'самомотивация' 'мо...</td>\n",
       "      <td>['лечение' 'приступ' 'лень']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['лишать' 'девственность' 'бложик' 'происходит...</td>\n",
       "      <td>[NOUN, VERB, NOUN, DET, NOUN, ADV, SCONJ, PRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>popotam2</td>\n",
       "      <td>2009-07-15 20:24:31+00:00</td>\n",
       "      <td>GTD</td>\n",
       "      <td>13</td>\n",
       "      <td>3100</td>\n",
       "      <td>https://habr.com/ru/articles/64586/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>6.0</td>\n",
       "      <td>424</td>\n",
       "      <td>['развитие' 'работоспособность' 'организация' ...</td>\n",
       "      <td>['организация' 'рабочий' 'время' 'помощь' 'цвет']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['предлагать' 'вариант' 'сделать' 'организован...</td>\n",
       "      <td>[VERB, ADV, NUM, NOUN, VERB, PRON, ADV, ADJ, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author          publication_date hubs  comments  views  \\\n",
       "0   complex 2009-08-03 14:34:35+00:00  GTD        67   6800   \n",
       "1  popotam2 2009-07-15 20:24:31+00:00  GTD        13   3100   \n",
       "\n",
       "                                   url  reading_time individ/company  \\\n",
       "0  https://habr.com/ru/articles/66091/           2.0      individual   \n",
       "1  https://habr.com/ru/articles/64586/           1.0      individual   \n",
       "\n",
       "   bookmarks_cnt  text_length  \\\n",
       "0           25.0         2027   \n",
       "1            6.0          424   \n",
       "\n",
       "                                         tags_tokens  \\\n",
       "0  ['лень' 'учись' 'работать' 'самомотивация' 'мо...   \n",
       "1  ['развитие' 'работоспособность' 'организация' ...   \n",
       "\n",
       "                                        title_tokens  rating_new  \\\n",
       "0                       ['лечение' 'приступ' 'лень']         4.0   \n",
       "1  ['организация' 'рабочий' 'время' 'помощь' 'цвет']         1.0   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  ['лишать' 'девственность' 'бложик' 'происходит...   \n",
       "1  ['предлагать' 'вариант' 'сделать' 'организован...   \n",
       "\n",
       "                                       text_pos_tags  \n",
       "0  [NOUN, VERB, NOUN, DET, NOUN, ADV, SCONJ, PRON...  \n",
       "1  [VERB, ADV, NUM, NOUN, VERB, PRON, ADV, ADJ, C...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284895.000000\n",
       "mean       7571.855771\n",
       "std        7980.117174\n",
       "min           1.000000\n",
       "25%        2104.000000\n",
       "50%        5514.000000\n",
       "75%       10315.000000\n",
       "max      197359.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    282640.000000\n",
       "mean       7631.863576\n",
       "std        7983.445597\n",
       "min         101.000000\n",
       "25%        2168.000000\n",
       "50%        5575.000000\n",
       "75%       10372.000000\n",
       "max      197359.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Уберем слишком короткие (неинформативные) статьи\n",
    "display(df['text_length'].describe())\n",
    "df = df[df['text_length']>100].copy()\n",
    "df['text_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Убрали примерно 2000 неинформативных статей`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение шкалы оценок на основе рейтинга статьи,\n",
    "# Это будет таргет для предсказания оценки статьи\n",
    "neg_d = df[df['rating_new']<0]['rating_new'].describe()\n",
    "pos_d = df[df['rating_new']>0]['rating_new'].describe()\n",
    "\n",
    "def rating_func(row):\n",
    "    rate = row['rating_new']\n",
    "\n",
    "    if pos_d['25%'] >= rate >= neg_d['75%']:\n",
    "        return('neutral')\n",
    "    \n",
    "    elif pos_d['75%'] >= rate > pos_d['25%']:\n",
    "        return('positive')\n",
    "    elif rate > pos_d['75%']:\n",
    "        return('very positive')\n",
    "    \n",
    "    elif neg_d['75%'] > rate >= neg_d['25%']:\n",
    "        return('negative')\n",
    "    elif neg_d['25%'] > rate:\n",
    "        return('very negative')\n",
    "    \n",
    "df['rating_level'] = df.apply(rating_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем текстовые токены в единую строку, \n",
    "# Это будет наш главный признак для предсказания тем (хабов) статей\n",
    "df['text_combined'] = df['text_tokens'] + ' ' + df['title_tokens'] + ' ' + df['tags_tokens']\n",
    "\n",
    "# Сразу удалим ненужные столбцы для облегчения вычислений\n",
    "df = df.drop(columns=['tags_tokens', 'title_tokens', 'text_tokens']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем уникальные метки из тегов\n",
    "unique_labels = set()\n",
    "df['hubs'].str.split(', ').apply(unique_labels.update)  # Собираем уникальные метки\n",
    "label_to_index = {label: idx for idx, label in enumerate(sorted(unique_labels))}  # Маппинг меток в индексы\n",
    "\n",
    "# Преобразуем строки в списки индексов\n",
    "df['hubs_encoded'] = df['hubs'].apply(lambda x: [label_to_index[label] for label in x.split(', ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>hubs</th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "      <th>url</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>individ/company</th>\n",
       "      <th>bookmarks_cnt</th>\n",
       "      <th>text_length</th>\n",
       "      <th>rating_new</th>\n",
       "      <th>text_pos_tags</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>text_combined</th>\n",
       "      <th>hubs_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complex</td>\n",
       "      <td>2009-08-03 14:34:35+00:00</td>\n",
       "      <td>GTD</td>\n",
       "      <td>67</td>\n",
       "      <td>6800</td>\n",
       "      <td>https://habr.com/ru/articles/66091/</td>\n",
       "      <td>2.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2027</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[NOUN, VERB, NOUN, DET, NOUN, ADV, SCONJ, PRON...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['лишать' 'девственность' 'бложик' 'происходит...</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>popotam2</td>\n",
       "      <td>2009-07-15 20:24:31+00:00</td>\n",
       "      <td>GTD</td>\n",
       "      <td>13</td>\n",
       "      <td>3100</td>\n",
       "      <td>https://habr.com/ru/articles/64586/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>6.0</td>\n",
       "      <td>424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[VERB, ADV, NUM, NOUN, VERB, PRON, ADV, ADJ, C...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['предлагать' 'вариант' 'сделать' 'организован...</td>\n",
       "      <td>[80]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author          publication_date hubs  comments  views  \\\n",
       "0   complex 2009-08-03 14:34:35+00:00  GTD        67   6800   \n",
       "1  popotam2 2009-07-15 20:24:31+00:00  GTD        13   3100   \n",
       "\n",
       "                                   url  reading_time individ/company  \\\n",
       "0  https://habr.com/ru/articles/66091/           2.0      individual   \n",
       "1  https://habr.com/ru/articles/64586/           1.0      individual   \n",
       "\n",
       "   bookmarks_cnt  text_length  rating_new  \\\n",
       "0           25.0         2027         4.0   \n",
       "1            6.0          424         1.0   \n",
       "\n",
       "                                       text_pos_tags rating_level  \\\n",
       "0  [NOUN, VERB, NOUN, DET, NOUN, ADV, SCONJ, PRON...      neutral   \n",
       "1  [VERB, ADV, NUM, NOUN, VERB, PRON, ADV, ADJ, C...      neutral   \n",
       "\n",
       "                                       text_combined hubs_encoded  \n",
       "0  ['лишать' 'девственность' 'бложик' 'происходит...         [80]  \n",
       "1  ['предлагать' 'вариант' 'сделать' 'организован...         [80]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предсказания метрик precision, recall, f1-score и hamming-loss\n",
    "def calculate_metrics(\n",
    "    y_test: Union[List[int], np.ndarray],\n",
    "    y_pred: Union[List[int], np.ndarray],\n",
    "    average: str = '',\n",
    "    zero_division: int = 0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрик precision, recall, f1-score и hamming-loss\n",
    "\n",
    "    Параметры:\n",
    "        y_test: Истинные значения\n",
    "        y_pred: Предсказанные значения\n",
    "        average: Метод усреднения для метрик precision, recall и f1-score\n",
    "                       Может быть 'micro', 'macro'или 'weighted'\n",
    "        zero_division: Обработка деления на ноль в метриках (0 или 1).\n",
    "\n",
    "    Возвращает:\n",
    "        Dict: Словарь с метриками\n",
    "    \"\"\"\n",
    "    precision = round(precision_score(y_test, y_pred, average=average, zero_division=zero_division), 4)\n",
    "    recall = round(recall_score(y_test, y_pred, average=average, zero_division=zero_division), 4)\n",
    "    f1 = round(f1_score(y_test, y_pred, average=average, zero_division=zero_division), 4)\n",
    "    hamming = round(hamming_loss(y_test, y_pred), 4)\n",
    "\n",
    "    metrics = {'Precision': precision, 'Recall': recall,\n",
    "               'F1-Score': f1, 'Hamming Loss': hamming}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка для начинающих (для себя)**\n",
    "* Микро-метрики учитывают вклад каждого класса пропорционально его частоте\n",
    "* Макро-метрики вычисляются как среднее значение по всем классам без учета их частоты\n",
    "* Взвешенные метрики учитывают частоту каждого класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сэмпл датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`На 10% данных от датасета прогоним GridSearch и найдём оптимальные параметры для решения нашей задачи`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сэмпл данных - 10% от всего объёма\n",
    "sample_df = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Преобразование hubs_ecoded в формат матрицы с уникальными метками хабов\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_multi = mlb.fit_transform(sample_df['hubs_encoded'])\n",
    "\n",
    "# Удаляем метки, которые встречаются в менее чем 1% случаев\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "y_multi_reduced = selector.fit_transform(y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28264, 56)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Итого осталось 56 самых популярных хабов (тем)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хабы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нашим бейзлайном будет пайплайн TfidfVectorizer + OneVsRestClassifier(LogisticRegression)**\n",
    "\n",
    "Предсказание будем осуществлять только на основе объединенных признаков - текста статьи, её тегов и названия\n",
    "\n",
    "`TfidfVectorizer` преобразует текст в разреженную матрицу, а `OneVsRestClassifier` для каждой метки обучает отдельную линейную модель (`LogisticRegression`/`LinearSVC`), используя матрицу TF-IDF в качестве входных признаков\n",
    "\n",
    "Будем передавать в `GridSearchCV` различные параметры в пайплайн для нахождения наиболее оптимальных\n",
    "\n",
    "Для поиска лучших гиперпараметров внутри сетки будем использовать метрику `F1 с микро-усреднением`, поскольку она хорошо справляется с оценкой общей точности и полноты модели в задачах multilabel классификации на большом объеме данных с дисбалансом классов (наш случай)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "X = sample_df['text_combined']\n",
    "y_hubs = y_multi_reduced\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки для предсказания хабов (тем) статей\n",
    "X_train, X_test, y_train_h, y_test_h = train_test_split(X, y_hubs, test_size=0.25)\n",
    "\n",
    "# Базовый пайплайн: TfidfVectorizer + OneVsRestClassifier(LogisticRegression())\n",
    "# Для логистической регрессии будем использовать solver sag как наиболее оптимальный для нашей задачи\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000, solver='sag')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Лучшие параметры: {'clf__estimator': LinearSVC(), 'clf__estimator__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_params_h.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение сетки параметров\n",
    "params = {\n",
    "     'tfidf__max_features': [2500, 5000, 10000],  # Число признаков TF-IDF\n",
    "     'tfidf__ngram_range': [(1, 2)],  # Униграммы+биграммы\n",
    "     'clf__estimator': [LinearSVC(), LogisticRegression(solver='sag')],  # Тип модели\n",
    "     'clf__estimator__C': [0.1, 1],  # Регуляризация\n",
    "}\n",
    "\n",
    "# StratifiedKFold\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, params, cv=cv, scoring='f1_micro', n_jobs=6, verbose=2)\n",
    "grid_search.fit(X_train, y_train_h)\n",
    "\n",
    "# Лучшая комбинация параметров\n",
    "best_params_h = grid_search.best_params_\n",
    "print(\"Лучшие параметры:\", best_params_h)\n",
    "\n",
    "# Сохранение лучшей комбинации параметров\n",
    "joblib.dump(best_params_h, 'best_params_h.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro - {'Precision': 0.3123, 'Recall': 0.6637, 'F1-Score': 0.4248, 'Hamming Loss': 0.0186}\n",
      "macro - {'Precision': 0.2981, 'Recall': 0.6606, 'F1-Score': 0.3943, 'Hamming Loss': 0.0186}\n",
      "weighted - {'Precision': 0.3654, 'Recall': 0.6637, 'F1-Score': 0.4626, 'Hamming Loss': 0.0186}\n"
     ]
    }
   ],
   "source": [
    "# Оценка на тестовой выборке\n",
    "y_pred_h = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Расчёт метрик для предсказания хабов (тем)\n",
    "for i in ['micro', 'macro', 'weighted']:\n",
    "    lr_metrics = calculate_metrics(y_pred_h, y_test_h, i)\n",
    "    print(i,'-', lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Выводы`\n",
    "* LinearSVC показала себя как лучшая модель для предсказания хабов (тем) статей\n",
    "* Модель показывает хороший уровень Recall (66%) на всех видах метрик, что делает ее полезной для нашей задачи, чтобы не пропустить релевантные темы\n",
    "* Разрыв между Macro (39%) и Weighted (46%) F1-Score говорит о том, что модель недостаточно хорошо справляется с редкими классами\n",
    "* Низкое значение Hamming Loss (~2%) говорит о том, что модель делает небольшое количество ошибок на уровне отдельного предсказания для каждой темы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рейтинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающую и тестовую выборки для предсказания рейтинга статьи\n",
    "y_rating = sample_df['rating_level']\n",
    "y_rating = y_rating.map({'very negative': -2, 'negative': -1, 'neutral': 0, 'positive': 1, 'very positive': 2})\n",
    "X_train, X_test, y_train_r, y_test_r = train_test_split(X, y_rating, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_level\n",
       " 1    12326\n",
       " 0     8446\n",
       " 2     6287\n",
       "-1      835\n",
       "-2      370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим на распределение классов\n",
    "y_rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Наиболее частый класс - положительная оценка, наиболее редкий - очень негативная оценка`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Лучшие параметры: {'clf__estimator': LogisticRegression(solver='sag'), 'clf__estimator__C': 1, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_params_r.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, params, cv=cv, scoring='f1_micro', n_jobs=6, verbose=2)\n",
    "grid_search.fit(X_train, y_train_r)\n",
    "\n",
    "# Лучшая комбинация параметров\n",
    "best_params_r = grid_search.best_params_\n",
    "print(\"Лучшие параметры:\", best_params_r)\n",
    "\n",
    "# Сохранение лучшей комбинации параметров\n",
    "joblib.dump(best_params_r, 'best_params_r.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro - {'Precision': 0.4711, 'Recall': 0.4711, 'F1-Score': 0.4711, 'Hamming Loss': 0.5289}\n",
      "macro - {'Precision': 0.2633, 'Recall': 0.2779, 'F1-Score': 0.2593, 'Hamming Loss': 0.5289}\n",
      "weighted - {'Precision': 0.5653, 'Recall': 0.4711, 'F1-Score': 0.5004, 'Hamming Loss': 0.5289}\n"
     ]
    }
   ],
   "source": [
    "# Оценка на тестовой выборке\n",
    "y_pred_r = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Расчёт метрик для предсказания рейтинга\n",
    "for i in ['micro', 'macro', 'weighted']:\n",
    "    lr_metrics = calculate_metrics(y_pred_r, y_test_r, i)\n",
    "    print(i,'-', lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Выводы`\n",
    "* Logistic Regression показала себя как лучшая модель для предсказания рейтинга статей\n",
    "* Модель имеет адекватную производительность на уровне микро и взвешенных метрик для более частых классов\n",
    "* Низкие макро-метрики показывают, что модель плохо работает с редкими классами (очень низкие и низкие оценки)\n",
    "* Hamming Loss говорит о большом количестве ошибок (53%), что снижает практическую применимость модели, потребуется её доработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полный датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Теперь обучим модель и посчитаем метрики для полного набора данных`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для чистоты эксперимента уберём данные, которые были в sample_df\n",
    "df = df.drop(sample_df.index).copy()\n",
    "\n",
    "# Преобразование hubs_ecoded в формат матрицы с уникальными метками хабов\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_multi = mlb.fit_transform(df['hubs_encoded'])\n",
    "\n",
    "# Удаляем метки, которые встречаются в менее чем 1% случаев\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "y_multi_reduced = selector.fit_transform(y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254376, 58)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Итого осталось 58 самых популярных хабов (тем)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хабы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пайплайн с лучшими параметрами для предсказания хабов (тем) статей\n",
    "pipeline_h = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(max_iter=1000)))])\n",
    "\n",
    "# Настройка пайплайна с лучшими параметрами\n",
    "pipeline_h.set_params(**best_params_h)\n",
    "\n",
    "# Подготовка данных\n",
    "X = df['text_combined']\n",
    "y_hubs = y_multi_reduced\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки для предсказания хабов (тем) статей\n",
    "X_train, X_test, y_train_h, y_test_h = train_test_split(X, y_hubs, test_size=0.25)\n",
    "\n",
    "# Обучение и предсказание по лучшему пайплайну для хабов\n",
    "pipeline_h.fit(X_train, y_train_h)\n",
    "y_pred_h = pipeline_h.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro - {'Precision': 0.3828, 'Recall': 0.7205, 'F1-Score': 0.4999, 'Hamming Loss': 0.0167}\n",
      "macro - {'Precision': 0.377, 'Recall': 0.7084, 'F1-Score': 0.4766, 'Hamming Loss': 0.0167}\n",
      "weighted - {'Precision': 0.4405, 'Recall': 0.7205, 'F1-Score': 0.5361, 'Hamming Loss': 0.0167}\n"
     ]
    }
   ],
   "source": [
    "# Сохранение модели для предсказания хабов (тем) статей\n",
    "joblib.dump(pipeline_h, 'pipeline_h.pkl')\n",
    "\n",
    "# Загрузка модели\n",
    "#loaded_pipeline_h = joblib.load('best_pipeline_h.pkl')\n",
    "\n",
    "# Расчёт метрик\n",
    "for i in ['micro', 'macro', 'weighted']:\n",
    "    lr_metrics = calculate_metrics(y_pred_h, y_test_h, i)\n",
    "    print(i,'-', lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Выводы`\n",
    "* Высокий Recall (71%-72%) указывает, что модель способна эффективно обнаруживать большинство истинных тем в статьях\n",
    "* Низкий Hamming Loss (~2%) говорит о том, что в среднем модель делает мало ошибок на каждый пример, но это может быть обусловлено дисбалансом классов\n",
    "* Относительно низкий Precision (38%-44%) показывает, что модель склонна к ложноположительным срабатываниям\n",
    "* Модель имеет потенциал, но требует доработки, особенно в части повышения точности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рейтинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пайплайн с лучшими параметрами для предсказания рейтинга статей\n",
    "pipeline_r = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000, solver='sag')))])\n",
    "\n",
    "# Настройка пайплайна с лучшими параметрами\n",
    "pipeline_r.set_params(**best_params_r)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки для предсказания рейтинга статьи\n",
    "y_rating = df['rating_level']\n",
    "y_rating = y_rating.map({'very negative': -2, 'negative': -1, 'neutral': 0, 'positive': 1, 'very positive': 2})\n",
    "X_train, X_test, y_train_r, y_test_r = train_test_split(X, y_rating, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_level\n",
       " 1    110927\n",
       " 0     75106\n",
       " 2     57297\n",
       "-1      7468\n",
       "-2      3578\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Здесь видим похожую картину как на сэмпле данных: наиболее частый класс - положительная оценка, наиболее редкий - очень негативная оценка`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение и предсказание по лучшему пайплайну для рейтинга\n",
    "pipeline_r.fit(X_train, y_train_r)\n",
    "y_pred_r = pipeline_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro - {'Precision': 0.496, 'Recall': 0.496, 'F1-Score': 0.496, 'Hamming Loss': 0.504}\n",
      "macro - {'Precision': 0.2889, 'Recall': 0.4111, 'F1-Score': 0.288, 'Hamming Loss': 0.504}\n",
      "weighted - {'Precision': 0.5604, 'Recall': 0.496, 'F1-Score': 0.5173, 'Hamming Loss': 0.504}\n"
     ]
    }
   ],
   "source": [
    "# Сохранение модели для предсказания рейтинга статей\n",
    "joblib.dump(pipeline_r, 'pipeline_r.pkl')\n",
    "\n",
    "# Расчёт метрик\n",
    "for i in ['micro', 'macro', 'weighted']:\n",
    "    lr_metrics = calculate_metrics(y_pred_r, y_test_r, i)\n",
    "    print(i,'-', lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Выводы`\n",
    "* Метрика Hamming Loss (~50%) говорит о том, что модель правильно классифицирует половину случаев, что недостаточно для её практического применения\n",
    "* Низкие макро-метрики по сравнению с взвешенными и микро-метриками указывают на то, что модель хуже справляется с редкими классами (очень низкие и низкие оценки)\n",
    "* Одинаковые значения Precision, Recall и F1 (~50%) в микро-метриках указывают на сбалансированную производительность по основным классам, но ещё есть пространство для улучшений\n",
    "* Текущая модель имеет ограниченную эффективность и требует доработки. Основные проблемы связаны с дисбалансом классов и неспособностью модели правильно классифицировать редкие оценки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
