### Основные выводы
**Предсказание хабов (тем) статей**
* Высокий Recall (~71%) указывает, что модель способна эффективно обнаруживать большинство истинных тем в статьях
* Низкий Hamming Loss (~2%) говорит о том, что в среднем модель делает мало ошибок на каждый пример, но это может быть обусловлено дисбалансом классов
* Относительно низкий Precision (~40%) показывает, что модель склонна к ложноположительным срабатываниям
* Модель имеет потенциал, но требует доработки, особенно в части повышения точности

**Предсказание рейтинга статей**
* Высокий Hamming Loss (~51%) говорит о том , что модель правильно классифицирует менее половины случаев, что недостаточно для практического применения
* Низкие макро-метрики по сравнению с взвешенными и микро-метриками указывают на то, что модель хуже справляется с редкими классами (очень низкими и низкие оценки)
* Одинаковые значения Precision, Recall и F1 (49%) в микро-метриках указывают на сбалансированную производительность по основным классам, но на недостаточно высоком уровне 
* Низкий Precision говорит о большом количестве ложноположительных предсказаний
* Текущая модель имеет ограниченную эффективность и требует доработки. Основные проблемы связаны с дисбалансом классов и неспособностью модели правильно классифицировать редкие оценки

**Что стоит улучшить/добавить на следующей итерации**
* Добавить остальные признаки (в текущей версии модель делает предсказание только на основе текста, названия и тегов статьи)
* Применить для задачи более сложные (нелинейные) модели
* Протестировать методы для балансировки классов (oversampling/undersampling и другие)
