### Основные выводы
**Предсказание хабов (тем) статей**
* Высокий Recall (~70%) (особенно микро и взвешенный) указывает, что модель способна эффективно обнаруживать большинство истинных тем в статьях
* Низкий Hamming Loss (~2%) говорит о том, что в среднем модель делает мало ошибок на каждый пример, но это может быть обусловлено дисбалансом классов
* Относительно Низкий Precision (~30%) показывает, что модель склонна к ложноположительным срабатываниям
* Разница между макро- и взвешенными метриками указывает на проблемы с предсказанием редких тем
* Модель имеет потенциал, но требует доработки, особенно в части повышения точности

**Предсказание рейтинга статей**
* Высокий Hamming Loss (~51%) говорит о том , что модель правильно классифицирует менее половины случаев, что недостаточно для практического применения
* Низкие макро-метрики по сравнению с взвешенными и микро-метриками указывают на то, что модель хуже справляется с редкими классами (очень низкими и низкие оценки)
* Высокая полнота в сочетании с низкой точностью свидетельствует о большом количестве ложноположительных предсказаний
* Текущая модель имеет ограниченную эффективность и требует доработки. Основные проблемы связаны с дисбалансом классов и неспособностью модели правильно классифицировать редкие оценки

**Что стоит улучшить/добавить на следующей итерации**
* Добавить остальные признаки (в текущей версии модель делает предсказание только на основе текста, названия и тегов статьи)
* Применить для задачи более сложные (нелинейные) модели
* Протестировать методы для балансировки классов (oversampling/undersampling и другие)
